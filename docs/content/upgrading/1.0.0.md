---
title: 1.0.0+ Upgrade Notice
weight: 2
description: Migrating from Gloo 0.x to Gloo 1.0.0 
---

- [Breaking Changes From 0.x to 1.0.0](#breaking-changes-from-0x-to-100)
    - [Breaking Changes Commonly Requiring Manual Action](#breaking-changes-commonly-requiring-manual-action)
    - [All Breaking Changes](#all-breaking-changes)
- [Example Upgrade Process](#example-upgrade-process)

We have officially released Gloo 1.0.0! This major version bump comes with a number of breaking changes
that you will have to keep in mind as you upgrade from Gloo 0.x to 1.0.0+. The easiest upgrade process
will be to start with a totally fresh installation of Gloo. However, this guide is provided in case you
would like to migrate an existing installation of Gloo from 0.x to 1.0.0+.

## Breaking Changes From 0.x to 1.0.0

### Breaking Changes Commonly Requiring Manual Action

These breaking changes are common pain points that most users will have to address, and which we specifically
would like to draw attention to. For a complete list of all breaking changes,
see [all breaking changes](#all-breaking-changes).

- Route objects (in Virtual Hosts) have had their `matcher` field (see
[here](https://github.com/solo-io/gloo/blob/v0.21.1/projects/gateway/api/v1/virtual_service.proto#L193)
in 0.21.1) changed to `matchers` (see [here](https://github.com/solo-io/gloo/blob/v1.0.0/projects/gateway/api/v1/virtual_service.proto#L188)
in 1.0.0) to support an array of multiple matchers. https://github.com/solo-io/gloo/issues/1171
- Upstreams have been flattened, entirely removing the `UpstreamSpec` proto message (see
[here](https://github.com/solo-io/gloo/blob/v0.21.1/projects/gloo/api/v1/plugins.proto#L196) in 0.21.1) and moving
all the associated fields into the top-level Upstream (see [here]
(https://github.com/solo-io/gloo/blob/v1.0.0/projects/gloo/api/v1/upstream.proto#L34) in 1.0.0).
https://github.com/solo-io/gloo/issues/1171
- The suffix `v2` has been dropped from the `gateway-v2` and `gateway-proxy-v2` deployments. After you complete
this upgrade, you will have old deployments and pods remaining in your namespace with the `v2` suffix. You may run 

```shell script
namespace=gloo-system
kubectl delete deployment gateway-v2 gateway-proxy-v2 -n $namespace
```
to clean up the old pods. https://github.com/solo-io/gloo/issues/1171

### All Breaking Changes

{{% expand "Click to see the complete list of breaking changes from 0.x to 1.0.0" %}}
- Rename the Gateway field tcpGateway.destinations to tcpGateway.tcpHosts in order to eliminate the duplicated field names (i.e., tcpGateway.destinations[].destination) (https://github.com/solo-io/gloo/issues/1171)
- Remove deprecated v1 Gateway in favor of v2 Gateway; rename v2 gateway resources to v1. (https://github.com/solo-io/gloo/issues/1171)
- When a Gateway has an empty httpGateway.virtualServices ref list, include all virtual services in the same namespace as the gateway. Previously the behavior was to include all virtual services in the cluster, which is unfriendly to multi-tenant setups. (https://github.com/solo-io/gloo/issues/1142)
- Move the Helm values field "installConfig.installationId" to "global.glooInstallationId" in order to better facilitate usage of the Gloo sub-chart in Gloo Enterprise (https://github.com/solo-io/gloo/issues/1635)
- Remove some deprecated APIs:
- Remove CorsPolicy from Gateway and Gloo VirtualHost, prefer setting CorsPolicy on VirtualHostPlugins.
- Remove name from gateway VirtualHost, was previously ignored.
- Remove bind_addr and circuit_breakers from Settings, prefer gloo.xdsBindAddr and gloo.circuitBreakers on same message. (https://github.com/solo-io/gloo/issues/1171)
- Rename all instances of plugins to options in Gloo's API. This prevents confusion as Gloo "plugins" is really an implementation detail for devs, and Gloo does not currently support dynamically-loaded plugins (aside from ExtAuth plugins).
- Update ExtAuth secret API to use strongly-typed configuration. OAuth and ApiKey secrets are no longer configured in the opaque extensions block, the same configuration lives at the top level in the api_key and oauth blocks. (https://github.com/solo-io/gloo/issues/1171) 
- Refactor the Upstream API to remove the upstreamSpec field, bringing all the fields contained in upstreamSpec up one level to the top-level Upstream. (https://github.com/solo-io/gloo/issues/1171)
- This release changes the names of Gloo's ClusterRoles. By default, cluster-scoped roles will have the namespace of the associated Gloo installation appended to their name (i.e., the cluster-scoped role "gloo-resource-reader" created along with a Gloo installation to the gloo-system namespace will now become "gloo-resource-reader-gloo-system"). This may cause a problem during upgrades from Gloo <0.21.0 to Gloo >=0.21.0 for both open-source and enterprise Gloo, as the role ref in a ClusterRoleBinding is immutable. To resolve this, you can delete the existing ClusterRoleBindings with "kubectl delete clusterrolebinding -l app=gloo" and they will be recreated correctly by the rest of the upgrade process. (https://github.com/solo-io/gloo/issues/1459)
- Make FDS default to whitelist mode (https://github.com/solo-io/gloo/issues/1171)
- Flatten prefix rewrite and host rewrite APIs. Move auto_host_rewrite from static upstream to route plugins since it's a route-level Envoy config; this fixes confusing behavior where a single static upstream on a route sets auto_host_rewrite for the entire route. (https://github.com/solo-io/gloo/issues/1171)
- Add support for multiple matchers on a Gateway/Gloo Route to reduce user duplication in yaml/user code. Also allows users to omit matchers on routes (the / prefix matcher will be used) to allow all requests to match the route. (https://github.com/solo-io/gloo/issues/1171)
- Remove deprecated messages from rbac and jwt. (https://github.com/solo-io/gloo/issues/1171)
- Remove deprecated messages from waf. (https://github.com/solo-io/gloo/issues/1171)
- Remove the glooctl --version command in favor of glooctl version (https://github.com/solo-io/gloo/issues/1285)
- Update glooctl to write using the new strongly-typed API. (https://github.com/solo-io/gloo/issues/1171)
- Remove some deprecated APIs:
    - weighed_destination_plugins on WeightedDestinations, prefer weighted_destination_plugins
    - gateway_proxy_name on Gateway, prefer proxy_names
    - role_arns on UpstreamSpec, prefer role_arn
    - Extauth's VhostExtension and RouteExtension, among other minor removals. Prefer configuring Gloo Enterprise ExtAuth using AuthConfig Custom Resources, and configure Virtual Services via ExtAuthExtension to either reference these AuthConfigs or reference your own custom auth implementation using CustomAuth. (https://github.com/solo-io/gloo/issues/1171)
- Proto messages have been updated as such: 
    - `VirtualHostPlugins -> VirtualHostOptions`
    - `RoutePlugins -> RouteOptions`
    - `WeightedDestinationPlugins -> WeightedDestinationOptions`
    - `ListenerPlugins -> ListenerOptions`
    - `HttpListenerPlugins -> HttpListenerOptions`
    - `TcpListenerPlugins -> TcpListenerOptions`
    
    When referenced in yaml, each property is referenced as options under the appropriate containing resource. (https://github.com/solo-io/gloo/issues/1171) 
{{% /expand %}}

## Example Upgrade Process

{{% notice note %}}
You should also read our usual upgrade guide (found [here](../upgrade_steps)) and our upgrade FAQ (found
[here](../faq)), both of which may also contain useful tips for performing Gloo upgrades in general.
{{% /notice %}}

In this section, we will walk through the process of upgrading a very simple Gloo installation (running in
minikube) from 0.21.1 to 1.0.0. While this will not cover everyone's use case, it will be useful to see how 
to resolve the most common breakages. We will be routing to an instance of [httpbin](https://httpbin.org/)
running in our cluster. Skip to the bottom for all the commands mentioned below in one bash script.

{{% notice note %}}
This guide will assume that you are running Gloo in the gloo-system namespace.
{{% /notice %}}

{{% expand "Click to see the YAML used to set up the httpbin deployment and VirtualService" %}}
```yaml
apiVersion: v1
kind: Service
metadata:
  name: httpbin
  namespace: default
  labels:
    app: httpbin
spec:
  ports:
  - name: http
    port: 8000
    targetPort: 80
  selector:
    app: httpbin
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: httpbin
  namespace: default
spec:
  replicas: 1
  selector:
    matchLabels:
      app: httpbin
      version: v1
  template:
    metadata:
      labels:
        app: httpbin
        version: v1
    spec:
      containers:
      - image: docker.io/kennethreitz/httpbin
        imagePullPolicy: IfNotPresent
        name: httpbin
        ports:
        - containerPort: 80

---
apiVersion: gateway.solo.io/v1
kind: VirtualService
metadata:
  name: httpbin-vs
  namespace: gloo-system
spec:
  virtualHost:
    domains:
    - '*'
    routes:
    - matcher:
        prefix: /
      routeAction:
        single:
          upstream:
            name: default-httpbin-8000
            namespace: gloo-system
```
{{% /expand %}}

We can see that we are running 0.21.1:

```shell script
~ > glooctl version
Client: {"version":"0.21.1"}
Server: {"type":"Gateway","kubernetes":{"containers":[{"Tag":"0.21.1","Name":"discovery","Registry":"quay.io/solo-io"},{"Tag":"0.21.1","Name":"gloo-envoy-wrapper","Registry":"quay.io/solo-io"},{"Tag":"0.21.1","Name":"gateway","Registry":"quay.io/solo-io"},{"Tag":"0.21.1","Name":"gloo","Registry":"quay.io/solo-io"}],"namespace":"gloo-system"}}
```

And we can successfully curl httpbin through Envoy:

```shell script
~ > curl -s $(glooctl proxy url)/status/418 # https://httpstatuses.com/418
    
        -=[ teapot ]=-
    
           _...._
         .'  _ _ `.
        | ."` ^ `". _,
        \_;`"---"`|//
          |       ;/
          \_     _/
            `"""`
```

Now we start the upgrade process. Before we begin, we may want to dump the current Gloo state to a file.

```shell script
~ > glooctl debug yaml > gloo-state-backup.yaml
```

First delete the existing Settings custom resource; we added the field `invalidConfigPolicy` which Gloo
0.x will not recognize.

```shell script
~ > kubectl delete settings default -n gloo-system
settings.gloo.solo.io "default" deleted
```

Delete your existing Gateway custom resources; they have been renamed, so if you don't delete them then
you will have redundant copies in the cluster (with the old names). Also delete the `gateway-v2` and
`gateway-proxy-v2` deployments, which have also been renamed. You can delete your Proxy custom resources
too; they will be recreated by the gloo pod, which is the controller for Proxy objects.

```shell script
~ > kubectl delete gateways.gateway.solo.io.v2 gateway-proxy-v2 gateway-proxy-v2-ssl -n gloo-system
gateway.gateway.solo.io.v2 "gateway-proxy-v2" deleted
gateway.gateway.solo.io.v2 "gateway-proxy-v2-ssl" deleted
~ > kubectl delete deployment gateway-v2 gateway-proxy-v2 -n gloo-system
deployment.extensions "gateway-v2" deleted
deployment.extensions "gateway-proxy-v2" deleted
~ > kubectl delete proxy gateway-proxy-v2 -n gloo-system
proxy.gloo.solo.io "gateway-proxy-v2" deleted
```

{{% notice note %}}
If you are running Gloo <0.18, the `Gateway` objects are named differently. You'll have to do:
```shell script
~ > kubectl delete gateway gateway gateway-ssl -n gloo-system
```

```shell script
~ > kubectl delete deployment gateway-proxy
deployment.extensions "gateway-proxy" deleted
```
{{% /notice %}}

{{% notice warning %}}
If you are running Gloo <0.18, you will also have to delete the `gateway-proxy` deployment. This is
where we run Envoy, so this will definitely cause downtime.

```shell script
~ > kubectl delete deployment gateway-proxy
deployment.extensions "gateway-proxy" deleted
```
{{% /notice %}}
The names of some cluster-scoped RBAC resources have changed. Delete them:

```shell script
# this is only necessary if you are running Gloo <0.21.0
kubectl delete clusterrole -l app=gloo
kubectl delete clusterrolebinding -l app=gloo
```

Now we upgrade `glooctl`:

```shell script
~ > glooctl upgrade --release=v1.0.0
downloading glooctl-darwin-amd64 from release tag v1.0.0
successfully downloaded and installed glooctl version v1.0.0 to /usr/local/bin/glooctl
```

Install Gloo in gateway mode through `glooctl`:

```shell script
~ > glooctl install gateway # ignore the version warning- we're in the middle of resolving it :)
----------
WARNING: glooctl@v1.0.0 has a different major version than the following server containers: discovery@v0.21.1, gloo-envoy-wrapper@v0.21.1, gateway@v0.21.1, gloo@v0.21.1

Consider running:
glooctl upgrade --release=v0.21.1
----------

Starting Gloo installation...
Installing CRDs...
Preparing namespace and other pre-install tasks...
Installing...

Gloo was successfully installed!
```

The Upstream spec has changed. Delete your dynamically-discovered upstreams. Any upstreams you have
which are manually configured must be adjusted by hand. Feel free to cycle the discovery pod after the
upstreams are deleted to ensure that they get recreated.

```shell script
~ > kubectl delete upstream -l discovered_by=kubernetesplugin -n gloo-system
... # snipped for brevity
~ > kubectl delete pod -l gloo=discovery -n gloo-system
pod "discovery-6d7cd86cfb-gscks" deleted
```

You will have to edit your Virtual Services to accommodate the `matcher` -> `matchers` change.
An example diff of the Virtual Service in the snippet above is:

```
~ > diff -u 0.x-vs.yaml 1.0-compliant-vs.yaml
  --- 0.x-vs.yaml
  +++ 1.0-compliant-vs.yaml
  @@ -8,8 +8,8 @@
       domains:
       - '*'
       routes:
  -    - matcher:
  -        prefix: /
  +    - matchers:
  +      - prefix: /
         routeAction:
           single:
             upstream:
```

Now Gloo should eventually get back into a good state. Run `glooctl check` to ensure this is the case:

```shell script
~ > glooctl check
Checking deployments... OK
Checking pods... OK
Checking upstreams... OK
Checking upstream groups... OK
Checking secrets... OK
Checking virtual services... OK
Checking gateways... OK
Checking proxies... OK
No problems detected.
```

And curl httpbin again to ensure that the proxy is operational:

```shell script
~ > curl -s $(glooctl proxy url)/status/418

    -=[ teapot ]=-

       _...._
     .'  _ _ `.
    | ."` ^ `". _,
    \_;`"---"`|//
      |       ;/
      \_     _/
        `"""`
```

Done! Here are all the commands used above, summarized into one code block. Note that due to the eventually-consistent
nature of Kubernetes, your upgrade process will almost certainly not be as simple as just running these
commands as a bash script. However, this is provided to show a high-level view of what is involved in the process.

```shell script
glooctl debug yaml > gloo-state-backup.yaml
kubectl delete settings default -n gloo-system
kubectl delete gateways.gateway.solo.io.v2 gateway-proxy-v2 gateway-proxy-v2-ssl -n gloo-system
kubectl delete deployment gateway-v2 gateway-proxy-v2 -n gloo-system
kubectl delete proxy gateway-proxy-v2 -n gloo-system
kubectl delete clusterrole -l app=gloo
kubectl delete clusterrolebinding -l app=gloo
glooctl upgrade --release=v1.0.0
glooctl install gateway
kubectl delete upstream -l discovered_by=kubernetesplugin -n gloo-system
kubectl delete pod -l gloo=discovery -n gloo-system
```
